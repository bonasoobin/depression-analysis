{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "074b0806",
   "metadata": {},
   "source": [
    "### 2023년 네이버뉴스 크롤링 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cba036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이렇게하려고했으나 1~6페이지 크롤링 후 8페이지로 넘어가고 11,15,20페이지 크롤링함.. 왜지 대체왜지\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://search.naver.com/search.naver?where=news&query=%EC%9A%B0%EC%9A%B8%EC%A6%9D&sm=tab_opt&sort=0&photo=0&field=0&pd=3&ds=2023.01.01&de=2023.12.31&docid=&related=0&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so%3Ar%2Cp%3Afrom20230101to20231231&is_sug_officeid=0&office_category=0&service_area=0'\n",
    "\n",
    "options = Options()\n",
    "# Chrome 브라우저를 실행할 때 창 크기를 최대화하는 옵션을 추가\n",
    "options.add_argument(\"--start-maximized\")\n",
    "# \"detach\"라는 실험적인 옵션을 추가하여 브라우저 창을 분리 가능하도록 설정\n",
    "options.add_experimental_option(\"detach\", True)\n",
    "driver = webdriver.Chrome(options = options)\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "title = []\n",
    "text = []\n",
    "\n",
    "for i in range(1, 11):\n",
    "    page = driver.find_element(By.XPATH, f'/html/body/div[3]/div[2]/div/div[1]/div[2]/div/div/a[{i}]')\n",
    "    page.click()\n",
    "    time.sleep(2)\n",
    "    for j in range(1, 11):\n",
    "        try:\n",
    "            title_a = driver.find_element(By.XPATH, f'/html/body/div[3]/div[2]/div/div[1]/section[1]/div/div[2]/ul/li[{j}]/div/div/div[2]/a[2]')\n",
    "        except:\n",
    "            title_a = driver.find_element(By.XPATH, f'/html/body/div[3]/div[2]/div/div[1]/section[1]/div/div[2]/ul/li[{j}]/div/div/div[2]/a')\n",
    "        title_text = title_a.text\n",
    "        title.append(title_text)\n",
    "#         print(title_text)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        text_a = driver.find_element(By.XPATH, f'/html/body/div[3]/div[2]/div/div[1]/section[1]/div/div[2]/ul/li[{j}]/div/div/div[2]/div/div/a')\n",
    "        text_text = text_a.text\n",
    "        text.append(text_text)\n",
    "        print(text_text)\n",
    "        print('\\n')\n",
    "        time.sleep(2)\n",
    "    time.sleep(2)\n",
    "    \n",
    "df = pd.DataFrame({'Title': title, 'Text': text})\n",
    "df.to_csv(r'C:\\Users\\soobin\\coding_excuse\\crawling_soobin.csv',index=False, encoding='utf-8-sig')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b541f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "63fcb394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예림언니 코드로 한것\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://search.naver.com/search.naver?where=news&query=%EC%9A%B0%EC%9A%B8%EC%A6%9D&sm=tab_opt&sort=0&photo=0&field=0&pd=3&ds=2023.01.01&de=2023.12.31&docid=&related=0&mynews=0&office_type=0&office_section_code=0&news_office_checked=&nso=so%3Ar%2Cp%3Afrom20230101to20231231&is_sug_officeid=0&office_category=0&service_area=0'\n",
    "res = requests.get(url)\n",
    "\n",
    "def get_news_from_page(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    page_titles = []\n",
    "    page_texts = []\n",
    "\n",
    "    # 제목과 관련된 텍스트 수집\n",
    "    for a_tag in soup.find_all('a', class_='news_tit'):\n",
    "        page_titles.append(a_tag.get_text())\n",
    "\n",
    "    # 본문과 관련된 텍스트 수집\n",
    "    for a_tag in soup.find_all('a', class_='api_txt_lines dsc_txt_wrap'):\n",
    "        page_texts.append(a_tag.get_text())\n",
    "\n",
    "    return page_titles, page_texts\n",
    "\n",
    "base_url = 'https://search.naver.com/search.naver?where=news&query=%EC%9A%B0%EC%9A%B8%EC%A6%9D&sm=tab_opt&sort=0&photo=0&field=0&pd=3&ds=2023.01.01&de=2023.12.31&start={}'\n",
    "\n",
    "titles = []\n",
    "texts = []\n",
    "\n",
    "# 10 페이지까지 반복\n",
    "for page in range(1, 11):\n",
    "    start = (page - 1) * 10 + 1\n",
    "    page_url = base_url.format(start)\n",
    "    page_titles, page_texts = get_news_from_page(page_url)\n",
    "    titles.extend(page_titles)\n",
    "    texts.extend(page_texts)\n",
    "    \n",
    "# 데이터프레임 생성 및 CSV 파일로 저장\n",
    "df = pd.DataFrame({'title': titles, 'text': texts})\n",
    "csv_file_path = 'news_data_sb.csv'\n",
    "df.to_csv(csv_file_path, index=False, encoding = 'utf-8-sig')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
